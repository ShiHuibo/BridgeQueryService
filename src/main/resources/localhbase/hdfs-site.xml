<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

    <property>
        <name>dfs.replication</name>
        <value>2</value>
        <description>
            the number of the same block
        </description>
    </property>

    <property>
        <name>dfs.nameservices</name>
        <value>hadoopCluster</value>
        <description>
            the name of HDFS cluster, notes the number of clusters can be larger than one.
        </description>
    </property>

    <property>
        <name>dfs.ha.namenodes.hadoopCluster</name>
        <value>myhadoop1,myhadoop2</value>
        <description>
            the name of namenodes, notes the number of namenodes can be larger than one.
        </description>
    </property>

    <property>
        <name>dfs.namenode.rpc-address.hadoopCluster.myhadoop1</name>
        <value>myhadoop1:9000</value>
        <description>
            the RPC url of the myhadoop1 which is a namenode.
        </description>
    </property>

    <property>
        <name>dfs.namenode.http-address.hadoopCluster.myhadoop1</name>
        <value>myhadoop1:50070</value>
        <description>
            the HTTP url of the myhadoop1 which is a namenode.
        </description>
    </property>

    <property>
        <name>dfs.namenode.rpc-address.hadoopCluster.myhadoop2</name>
        <value>myhadoop2:9000</value>
        <description>
            the RPC url of the myhadoop2 which is a namenode.
        </description>
    </property>

    <property>
        <name>dfs.namenode.http-address.hadoopCluster.myhadoop2</name>
        <value>myhadoop2:50070</value>
        <description>
            the HTTP url of the myhadoop2 which is a namenode.
        </description>
    </property>

    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://myhadoop1:8485;myhadoop2:8485;myhadoop3:8485/hadoopCluster</value>
        <description>A directory on shared storage between the multiple namenodes
            in an HA cluster. This directory will be written by the active and read
            by the standby in order to keep the namespaces synchronized. This directory
            does not need to be listed in dfs.namenode.edits.dir above. It should be
            left empty in a non-HA cluster.
        </description>
    </property>

    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
        <description>
            automatic-failover enabled or not, if enabled, when namenode is failure, another namenode will be active.
        </description>
    </property>

    <property>
        <name>dfs.client.failover.proxy.provider.hadoopCluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
        <description>
            when namenode is failure, which implementation class is responsible for performing the fault switch.
        </description>
    </property>

    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
        <description>
            Once you need NameNode to switch, use the SSH method to operate.
        </description>
    </property>

    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/hadoop/.ssh/id_rsa</value>
        <description>
            If the SSH is used for fault switching, the location of the key stored in the SSH communication is used.
        </description>
    </property>

    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/home/hadoop/bigdata/workspace/journal</value>
        <description>
            journalnode's disk address
        </description>
    </property>

    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/home/hadoop/bigdata/workspace/namenode/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/home/hadoop/bigdata/workspace/datanode/data</value>
    </property>

</configuration>
